{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import genfromtxt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename, skiprows = 1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = np.array(load_data(\"training_data.txt\", skiprows = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = training_data[:, 0]\n",
    "X_train = training_data[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = np.array(load_data(\"test_data.txt\"))\n",
    "X_test = test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting aside Valdiation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training, X_testing, y_training, y_testing = train_test_split(X_train, y_train, test_size=0.1, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_clf_error(y_pred, y_correct):\n",
    "    '''Predicts binary classification error'''\n",
    "    binarytrain_number = (y_pred!=y_correct).sum()\n",
    "    return binarytrain_number/len(y_pred)\n",
    "\n",
    "#Doing Logistic regression\n",
    "log_reg = LogisticRegression(C = 0.15)\n",
    "_ = log_reg.fit(X_training, y_training)\n",
    "y_pred_log = log_reg.predict(X_training)\n",
    "y_test_pred_log = log_reg.predict(X_testing)\n",
    "y_actual_test_log = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12566666666666668"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_clf_error(y_pred_log, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14449999999999999"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_clf_error(y_test_pred_log, y_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13038888888888889"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_regression_train = y_training\n",
    "y_regression_train[y_regression_train==0] = -1\n",
    "\n",
    "y_regression_test = y_testing\n",
    "y_regression_test[y_regression_test==0] = -1\n",
    "\n",
    "#This is approximately the best one found\n",
    "#Test error is like 0.1519\n",
    "streng = 130\n",
    "\n",
    "ridge = Ridge(alpha = 130)\n",
    "ridge.fit(X_training, y_regression_train)   \n",
    "\n",
    "y_pred_ridge = np.sign(ridge.predict(X_training))\n",
    "y_test_pred_ridge = np.sign(ridge.predict(X_testing))\n",
    "y_actual_test_ridge = np.sign(ridge.predict(X_test))\n",
    "\n",
    "#Finding error\n",
    "binary_clf_error(y_pred_ridge, y_regression_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15049999999999999"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_clf_error(y_test_pred_ridge, y_regression_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13300000000000001"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is approximately the best one found\n",
    "#It got like 85% test accuracy.\n",
    "streng = 0.00055\n",
    "\n",
    "lasso = Lasso(alpha = streng)\n",
    "lasso.fit(X_training, y_regression_train) \n",
    "\n",
    "y_pred_lasso = np.sign(lasso.predict(X_training))\n",
    "y_test_pred_lasso = np.sign(lasso.predict(X_testing))\n",
    "y_actual_test_lasso = np.sign(lasso.predict(X_test))\n",
    "\n",
    "#Finding error\n",
    "binary_clf_error(y_pred_lasso, y_regression_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13650000000000001"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_clf_error(y_test_pred_lasso, y_regression_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12811111111111112"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_clf_error(np.sign(np.mean([y_pred_lasso, y_pred_ridge, y_pred_log], axis =0)), y_regression_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15049999999999999"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_clf_error(np.sign(np.mean([y_test_pred_lasso, y_test_pred_ridge, y_test_pred_log], axis =0)), y_regression_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1., -1., ..., -1.,  1.,  1.])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = np.linspace(0.0, 0.2, num=5)\n",
    "training_error_list = []\n",
    "validation_error_list = []\n",
    "\n",
    "for c_value in c_values:\n",
    "    #Initializing Kfold cv object\n",
    "    kf = KFold(n_splits=15, shuffle = True)\n",
    "    log_reg = LogisticRegression(C = 0.15)\n",
    "    _ = log_reg.fit(X_training, y_training)\n",
    "    \n",
    "    \n",
    "    training_error = []\n",
    "    validation_error = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        #Running Logistic regression on training partition\n",
    "        \n",
    "        training_error = (1-c_value)*y_test_pred_log+c_value*y_test_pred_ridge\n",
    "        \n",
    "        #Finding training error \n",
    "        training_error.append(binary_clf_error(log_reg.predict(X_training), y_training))\n",
    "\n",
    "        #Finding validation error\n",
    "        validation_error.append(binary_clf_error(log_reg.predict(X_testing), y_testing))\n",
    "    training_error_list.append(np.mean(training_error))\n",
    "    validation_error_list.append(np.mean(validation_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.45 ,  0.475,  0.5  ,  0.525,  0.55 ]),\n",
       " [0.15075016880157072,\n",
       "  0.15070071865792534,\n",
       "  0.15110006887029107,\n",
       "  0.15104844426998804,\n",
       "  0.15015073108606988])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_values, validation_error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
